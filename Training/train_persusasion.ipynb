{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["0fZK09CCrweL","7Dh6UOIQD35M","o5CgysPPD7bE"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b86d9290759e42939e196b423c3f9e0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f7c75e963864cecb0f6e98e31dca2a6","IPY_MODEL_b3aab60882344dd0b0a5a162372eb84b","IPY_MODEL_9eeb8fcb895041e49b346a71ebd6343b"],"layout":"IPY_MODEL_e0bb7b34ae9447f98c194c5b4fafcf7c"}},"1f7c75e963864cecb0f6e98e31dca2a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_456292e59b3646e68a1eb50ce26fcae0","placeholder":"​","style":"IPY_MODEL_6f9b8a9135434ce79d69255f4c06b392","value":"Downloading (…)solve/main/vocab.txt: "}},"b3aab60882344dd0b0a5a162372eb84b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bddd842b4fef463699632e5320a8b1ec","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c46c9646361b4c07af985953953d037f","value":1}},"9eeb8fcb895041e49b346a71ebd6343b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9978d7b56f5a48039fe0ba3a9780ecef","placeholder":"​","style":"IPY_MODEL_b883fc483e2c465b82dd0f6933a10bf8","value":" 232k/? [00:00&lt;00:00, 9.34MB/s]"}},"e0bb7b34ae9447f98c194c5b4fafcf7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"456292e59b3646e68a1eb50ce26fcae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f9b8a9135434ce79d69255f4c06b392":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bddd842b4fef463699632e5320a8b1ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c46c9646361b4c07af985953953d037f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9978d7b56f5a48039fe0ba3a9780ecef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b883fc483e2c465b82dd0f6933a10bf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23943076867b4b84acf87a41a55ec36b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c153258629c04ee9844384e67d46b607","IPY_MODEL_a2c17993f9214221a593c4f2519006a7","IPY_MODEL_b2ee70ab66734e11bfff0ced3c60827c"],"layout":"IPY_MODEL_b4c9e1c8bcb34793b5dcc4ee34171232"}},"c153258629c04ee9844384e67d46b607":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0687bd35e0ee4d048ce5068d255bdce1","placeholder":"​","style":"IPY_MODEL_d71ae7ae799a47369923f82c1e608a12","value":"Downloading (…)okenizer_config.json: 100%"}},"a2c17993f9214221a593c4f2519006a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e205b5e645341ce964dff15ede33413","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2aa0d0712f544fc8b801bcf5367eb9fe","value":28}},"b2ee70ab66734e11bfff0ced3c60827c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94e4070421b3449d82aec4f32d471d29","placeholder":"​","style":"IPY_MODEL_b37dd3f4729a4d799d2c39e3ca815ced","value":" 28.0/28.0 [00:00&lt;00:00, 1.95kB/s]"}},"b4c9e1c8bcb34793b5dcc4ee34171232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0687bd35e0ee4d048ce5068d255bdce1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d71ae7ae799a47369923f82c1e608a12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e205b5e645341ce964dff15ede33413":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aa0d0712f544fc8b801bcf5367eb9fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94e4070421b3449d82aec4f32d471d29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b37dd3f4729a4d799d2c39e3ca815ced":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b2b2650b91d4d18bba3071d6069ff7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bed49f37ce1e4a8fabf02f4d7d363824","IPY_MODEL_7a29247c42d548c396a5cc405afdc1be","IPY_MODEL_f3560b5b7c284f8bbb631ee8746270a5"],"layout":"IPY_MODEL_7ed79ac628fe4a73a03ccd6abf817c07"}},"bed49f37ce1e4a8fabf02f4d7d363824":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ee1426e977548e789b6b71a38ffc098","placeholder":"​","style":"IPY_MODEL_76a74eb1d84749b883c07c934c2af245","value":"Downloading (…)lve/main/config.json: 100%"}},"7a29247c42d548c396a5cc405afdc1be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4363f3265b643dfb8a90a5a14cf3ff4","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a5c4e3600a34166b0fbc9c74c8f078f","value":570}},"f3560b5b7c284f8bbb631ee8746270a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38d86b51b53849a1859254edbe215406","placeholder":"​","style":"IPY_MODEL_1d34b64ebafc4d9c8cca2c6e522bbf3f","value":" 570/570 [00:00&lt;00:00, 40.9kB/s]"}},"7ed79ac628fe4a73a03ccd6abf817c07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ee1426e977548e789b6b71a38ffc098":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a74eb1d84749b883c07c934c2af245":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4363f3265b643dfb8a90a5a14cf3ff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a5c4e3600a34166b0fbc9c74c8f078f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38d86b51b53849a1859254edbe215406":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d34b64ebafc4d9c8cca2c6e522bbf3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39b6867015be45efa2ddac6c0fbff8b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_980bbbb953dc4f288ed23e5a2fa36c18","IPY_MODEL_4c771e833992432b95a8874c4c83eb86","IPY_MODEL_e6dc3664dfd54ca8886fbc76df0d49a5"],"layout":"IPY_MODEL_717b0f3d184948c080fb0e5bbdb95f3f"}},"980bbbb953dc4f288ed23e5a2fa36c18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ff288aab493442e84e695e96bbaebfe","placeholder":"​","style":"IPY_MODEL_25967c279e564d22800e0b64bdee29e2","value":"Downloading model.safetensors: 100%"}},"4c771e833992432b95a8874c4c83eb86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc6fbba17cae4705b3204f74ef02510b","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c7decc033c64f83ae9160765d1fbc97","value":440449768}},"e6dc3664dfd54ca8886fbc76df0d49a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6e7d7c3feef4a82af6d0f9f0f5400aa","placeholder":"​","style":"IPY_MODEL_27a59e583dc040b69f99e35d446d1569","value":" 440M/440M [00:01&lt;00:00, 333MB/s]"}},"717b0f3d184948c080fb0e5bbdb95f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ff288aab493442e84e695e96bbaebfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25967c279e564d22800e0b64bdee29e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc6fbba17cae4705b3204f74ef02510b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c7decc033c64f83ae9160765d1fbc97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6e7d7c3feef4a82af6d0f9f0f5400aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27a59e583dc040b69f99e35d446d1569":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# install and load dependancy"],"metadata":{"id":"0fZK09CCrweL"}},{"cell_type":"code","source":["!pip install transformers --quiet"],"metadata":{"id":"RvfFFm1Li-3u","executionInfo":{"status":"ok","timestamp":1687424475040,"user_tz":-120,"elapsed":18207,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2efadac-f214-48fc-efa6-1102ca859403"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","import tqdm\n","import yaml\n","import json\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision import transforms as T\n","\n","import logging\n","from torch.utils.tensorboard import SummaryWriter\n","from shutil import copyfile"],"metadata":{"id":"wJ8C5kD1h9SH","executionInfo":{"status":"ok","timestamp":1687424485805,"user_tz":-120,"elapsed":10776,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Link with Google Drive"],"metadata":{"id":"FIY0cG1RDwOK"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","path = '/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/'\n","sys.path.append(path)\n","\n","from dataset import SemEvalDataset, Collate\n","from models import MemeMultiLabelClassifier\n","from sampler import MultilabelBalancedRandomSampler\n","\n","from scorer import evaluate\n","from format_checker import read_classes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ddVhJVO7GR4H","executionInfo":{"status":"ok","timestamp":1687424576034,"user_tz":-120,"elapsed":90252,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"8a2210d1-0a9f-466f-c059-c1242f8910b8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Load data from drive"],"metadata":{"id":"NgWa1sB0DtJ3"}},{"cell_type":"code","source":["def load_data(config, path, workers, val_fold):\n","\n","    # Load data loaders\n","    test_transforms = T.Compose([T.Resize(256),\n","                    T.CenterCrop(224),\n","                    T.ToTensor(),\n","                    T.Normalize(mean=[0.485, 0.456, 0.406],\n","                                std=[0.229, 0.224, 0.225])])\n","    train_transforms = T.Compose([T.Resize(256),\n","                    T.RandomCrop(224),\n","                    T.ToTensor(),\n","                    T.Normalize(mean=[0.485, 0.456, 0.406],\n","                                std=[0.229, 0.224, 0.225])])\n","\n","    train_dataset = SemEvalDataset(config, path, split='train', transforms=train_transforms, val_fold=val_fold)\n","    val_dataset = SemEvalDataset(config, path, split='val', transforms=test_transforms, val_fold=val_fold)\n","\n","    id_intersection = set([x['id'] for x in train_dataset.targets]).intersection([x['id'] for x in val_dataset.targets])\n","    assert len(id_intersection) == 0\n","\n","    if config['dataset']['task'] == 3:\n","        classes = read_classes(path + 'techniques_list_task3.txt')\n","\n","    collate_fn = Collate(path, config, classes)\n","    if 'balanced-sampling' in config['training'] and config['training']['balanced-sampling']:\n","        classes_ids = [[train_dataset.class_list.index(x) for x in info['labels']] for info in train_dataset.targets]\n","        labels = np.zeros((len(classes_ids), len(train_dataset.class_list)))\n","        for l, c in zip(labels, classes_ids):\n","            l[c] = 1\n","        sampler = MultilabelBalancedRandomSampler(labels)\n","    else:\n","        sampler = None\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=config['training']['bs'], shuffle=True if sampler is None else False, num_workers=workers, collate_fn=collate_fn, sampler=sampler)\n","    val_dataloader = DataLoader(val_dataset, batch_size=config['training']['bs'], shuffle=False,\n","                                  num_workers=workers, collate_fn=collate_fn)\n","\n","    return train_dataloader, val_dataloader, classes"],"metadata":{"id":"9BCaDWX65u_A","executionInfo":{"status":"ok","timestamp":1687424576035,"user_tz":-120,"elapsed":12,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Train the model and validate"],"metadata":{"id":"7Dh6UOIQD35M"}},{"cell_type":"code","source":["def train_model(config, path, model, optimizer, scheduler, train_dataloader, val_dataloader, classes, num_epochs, log_step, val_step, val_fold):\n","    model.train()\n","\n","    start_epoch = 0\n","    mean_loss = 0\n","    progress_bar = tqdm.trange(start_epoch, num_epochs)\n","    progress_bar.set_description('Train')\n","    best_f1 = 0.0\n","\n","    for epoch in progress_bar:\n","        for it, (image, text, text_len, labels, ids) in enumerate(train_dataloader):\n","            global_iteration = epoch * len(train_dataloader) + it\n","\n","            if torch.cuda.is_available():\n","                image = image.cuda() if image is not None else None\n","                text = text.cuda()\n","                labels = labels.cuda()\n","\n","            optimizer.zero_grad()\n","\n","            loss = model(image, text, text_len, labels)\n","            loss.backward()\n","            optimizer.step()\n","            mean_loss += loss.item()\n","\n","            if global_iteration % log_step == 0:\n","                mean_loss /= log_step\n","                progress_bar.set_postfix(dict(loss='{:.2}'.format(mean_loss)))\n","                mean_loss = 0\n","\n","            if global_iteration % val_step == 0:\n","                # validate (using different thresholds)\n","                metrics = validate(val_dataloader, model, classes, thresholds=[0.3, 0.5, 0.8])\n","\n","                # save best model\n","                if metrics['macroF1_thr=0.3'] + metrics['microF1_thr=0.3'] > best_f1:\n","                    print('Saving best model...')\n","                    checkpoint = {\n","                        'cfg': config,\n","                        'epoch': epoch,\n","                        'model': model.joint_processing_module.state_dict() if not config['text-model']['fine-tune'] and not config['image-model']['fine-tune'] else model.state_dict()}\n","                    latest = os.path.join(path, 'model_best_fold{}.pt'.format(val_fold))\n","                    torch.save(checkpoint, latest)\n","                    best_f1 = metrics['macroF1_thr=0.3'] + metrics['microF1_thr=0.3']\n","\n","        print('Saving best model...')\n","        checkpoint = {\n","          'cfg': config,\n","          'epoch': epoch,\n","          'model': model.joint_processing_module.state_dict() if not config['text-model']['fine-tune'] and not config['image-model']['fine-tune'] else model.state_dict()}\n","        latest = os.path.join(path, 'model_best_fold{}.pt'.format(val_fold))\n","        torch.save(checkpoint, latest)\n","        best_f1 = metrics['macroF1_thr=0.3'] + metrics['microF1_thr=0.3']\n","        scheduler.step()"],"metadata":{"id":"3cU-90lc6Vsr","executionInfo":{"status":"ok","timestamp":1687424576036,"user_tz":-120,"elapsed":11,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def validate(val_dataloader, model, classes_list, thresholds=[0.3, 0.5, 0.8]):\n","    model.eval()\n","    predictions = []\n","    metrics = {}\n","    progress_bar = tqdm.tqdm(thresholds)\n","    progress_bar.set_description('Validation')\n","    for thr in progress_bar:\n","        for it, (image, text, text_len, labels, ids) in enumerate(val_dataloader):\n","            if torch.cuda.is_available():\n","                image = image.cuda() if image is not None else None\n","                text = text.cuda()\n","                labels = labels.cuda()\n","            with torch.no_grad():\n","                pred_classes = model(image, text, text_len, inference_threshold=thr)\n","\n","            for id, labels in zip(ids, pred_classes):    # loop over every element of the batch\n","                predictions.append({'id': id, 'labels': labels})\n","\n","        macro_f1, micro_f1 = evaluate(predictions, val_dataloader.dataset.targets, classes_list)\n","        metrics['macroF1_thr={}'.format(thr)] = macro_f1\n","        metrics['microF1_thr={}'.format(thr)] = micro_f1\n","\n","    model.train()\n","    return metrics"],"metadata":{"id":"vJQlJli_Gadv","executionInfo":{"status":"ok","timestamp":1687424576037,"user_tz":-120,"elapsed":11,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Training parameters"],"metadata":{"id":"o5CgysPPD7bE"}},{"cell_type":"code","source":["def start_training(config, path, val_fold=0):\n","    num_epochs = 80\n","    workers = 2\n","    log_step = 10\n","    val_step = 200\n","    test_step = 100000000\n","    logger_name = './runs/test'\n","\n","    if 'task' not in config['dataset']:\n","        config['dataset']['task'] = 3\n","\n","    train_dataloader, val_dataloader, classes = load_data(config, path, workers, val_fold)\n","\n","    # Construct the model\n","    model = MemeMultiLabelClassifier(config, labels=classes)\n","    if torch.cuda.is_available():\n","        model.cuda()\n","\n","    # Construct the optimizer\n","    if not config['text-model']['fine-tune'] and not config['image-model']['fine-tune']:\n","        optimizer = torch.optim.Adam([p for n, p in model.named_parameters() if 'textual_module' not in n and 'visual_module' not in n], lr=config['training']['lr'])\n","    else:\n","        if config['dataset']['task'] == 3:\n","            optimizer = torch.optim.Adam([\n","                {'params': [p for n, p in model.named_parameters() if 'textual_module' not in n and 'visual_module' not in n]},\n","                {'params': model.textual_module.parameters(), 'lr': config['training']['pretrained-modules-lr']},\n","                {'params': model.visual_module.parameters(), 'lr': config['training']['pretrained-modules-lr']}]\n","                , lr=config['training']['lr'])\n","\n","    # LR scheduler\n","    scheduler_name = config['training']['scheduler']\n","    if scheduler_name == 'steplr':\n","        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, gamma=config['training']['gamma'], milestones=config['training']['milestones'])\n","    elif scheduler_name is None:\n","        scheduler = None\n","    else:\n","        raise ValueError('{} scheduler is not available'.format(scheduler_name))\n","\n","    # Train the model\n","    train_model(config, path, model, optimizer, scheduler, train_dataloader, val_dataloader, classes, num_epochs, log_step, val_step, val_fold)\n"],"metadata":{"id":"LhVgM6eRGkQs","executionInfo":{"status":"ok","timestamp":1687424576038,"user_tz":-120,"elapsed":11,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Main function"],"metadata":{"id":"X2rKGBU9EAAj"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"U3m3-ueFF447","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b86d9290759e42939e196b423c3f9e0d","1f7c75e963864cecb0f6e98e31dca2a6","b3aab60882344dd0b0a5a162372eb84b","9eeb8fcb895041e49b346a71ebd6343b","e0bb7b34ae9447f98c194c5b4fafcf7c","456292e59b3646e68a1eb50ce26fcae0","6f9b8a9135434ce79d69255f4c06b392","bddd842b4fef463699632e5320a8b1ec","c46c9646361b4c07af985953953d037f","9978d7b56f5a48039fe0ba3a9780ecef","b883fc483e2c465b82dd0f6933a10bf8","23943076867b4b84acf87a41a55ec36b","c153258629c04ee9844384e67d46b607","a2c17993f9214221a593c4f2519006a7","b2ee70ab66734e11bfff0ced3c60827c","b4c9e1c8bcb34793b5dcc4ee34171232","0687bd35e0ee4d048ce5068d255bdce1","d71ae7ae799a47369923f82c1e608a12","0e205b5e645341ce964dff15ede33413","2aa0d0712f544fc8b801bcf5367eb9fe","94e4070421b3449d82aec4f32d471d29","b37dd3f4729a4d799d2c39e3ca815ced","5b2b2650b91d4d18bba3071d6069ff7a","bed49f37ce1e4a8fabf02f4d7d363824","7a29247c42d548c396a5cc405afdc1be","f3560b5b7c284f8bbb631ee8746270a5","7ed79ac628fe4a73a03ccd6abf817c07","3ee1426e977548e789b6b71a38ffc098","76a74eb1d84749b883c07c934c2af245","c4363f3265b643dfb8a90a5a14cf3ff4","3a5c4e3600a34166b0fbc9c74c8f078f","38d86b51b53849a1859254edbe215406","1d34b64ebafc4d9c8cca2c6e522bbf3f","39b6867015be45efa2ddac6c0fbff8b9","980bbbb953dc4f288ed23e5a2fa36c18","4c771e833992432b95a8874c4c83eb86","e6dc3664dfd54ca8886fbc76df0d49a5","717b0f3d184948c080fb0e5bbdb95f3f","3ff288aab493442e84e695e96bbaebfe","25967c279e564d22800e0b64bdee29e2","cc6fbba17cae4705b3204f74ef02510b","4c7decc033c64f83ae9160765d1fbc97","d6e7d7c3feef4a82af6d0f9f0f5400aa","27a59e583dc040b69f99e35d446d1569"]},"executionInfo":{"status":"ok","timestamp":1687425811556,"user_tz":-120,"elapsed":1235529,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"503ef2a7-99e5-45da-c720-67124eaf722b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b86d9290759e42939e196b423c3f9e0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23943076867b4b84acf87a41a55ec36b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2b2650b91d4d18bba3071d6069ff7a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_32_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vit_b_32-d86f8d99.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_32-d86f8d99.pth\n","100%|██████████| 337M/337M [00:06<00:00, 55.8MB/s]\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39b6867015be45efa2ddac6c0fbff8b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'cls.predictions.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.10.attention.output.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Train:   0%|          | 0/80 [00:13<?, ?it/s, loss=0.069]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:29<00:59, 29.75s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:31<00:13, 13.35s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:33<00:00, 11.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   0%|          | 0/80 [02:42<?, ?it/s, loss=0.25]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   1%|▏         | 1/80 [03:08<3:54:32, 178.13s/it, loss=0.26]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   2%|▎         | 2/80 [03:18<1:44:07, 80.10s/it, loss=0.21]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   4%|▍         | 3/80 [03:25<1:01:21, 47.82s/it, loss=0.22]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.45s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:02,  2.06s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   4%|▍         | 3/80 [03:37<1:01:21, 47.82s/it, loss=0.22]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   5%|▌         | 4/80 [03:45<46:19, 36.58s/it, loss=0.18]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   6%|▋         | 5/80 [03:57<33:21, 26.69s/it, loss=0.16]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   8%|▊         | 6/80 [04:09<26:32, 21.52s/it, loss=0.12]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.33s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:02,  2.02s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n","Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:   9%|▉         | 7/80 [04:27<24:41, 20.29s/it, loss=0.1] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  10%|█         | 8/80 [04:38<21:05, 17.58s/it, loss=0.086]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  11%|█▏        | 9/80 [04:47<18:22, 15.53s/it, loss=0.063]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  12%|█▎        | 10/80 [04:53<15:53, 13.63s/it, loss=0.052]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:03<00:06,  3.46s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:02,  2.54s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  12%|█▎        | 10/80 [05:05<15:53, 13.63s/it, loss=0.056]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  14%|█▍        | 11/80 [05:16<17:07, 14.89s/it, loss=0.044]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  15%|█▌        | 12/80 [05:28<15:35, 13.76s/it, loss=0.033]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  16%|█▋        | 13/80 [05:36<14:40, 13.14s/it, loss=0.03] \n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:03<00:07,  3.77s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:06<00:03,  3.08s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:08<00:00,  2.82s/it]\n","Train:  16%|█▋        | 13/80 [05:46<14:40, 13.14s/it, loss=0.031]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  18%|█▊        | 14/80 [05:56<15:55, 14.48s/it, loss=0.025]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  19%|█▉        | 15/80 [06:06<14:46, 13.63s/it, loss=0.02] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  20%|██        | 16/80 [06:18<13:08, 12.33s/it, loss=0.02] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  21%|██▏       | 17/80 [06:22<12:45, 12.15s/it, loss=0.019]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:03<00:06,  3.28s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:06<00:03,  3.13s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:08<00:00,  2.79s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  21%|██▏       | 17/80 [06:36<12:45, 12.15s/it, loss=0.016]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  22%|██▎       | 18/80 [06:50<14:16, 13.81s/it, loss=0.018]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  24%|██▍       | 19/80 [07:01<14:01, 13.80s/it, loss=0.016]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  25%|██▌       | 20/80 [07:09<13:12, 13.21s/it, loss=0.013]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:03<00:06,  3.40s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:06<00:03,  3.22s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:08<00:00,  2.78s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["\rTrain:  25%|██▌       | 20/80 [07:19<13:12, 13.21s/it, loss=0.014]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  26%|██▋       | 21/80 [07:31<14:19, 14.57s/it, loss=0.015]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  28%|██▊       | 22/80 [07:41<13:16, 13.73s/it, loss=0.011]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  29%|██▉       | 23/80 [07:52<11:44, 12.37s/it, loss=0.013]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  30%|███       | 24/80 [07:54<11:17, 12.10s/it, loss=0.0088]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.43s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:02,  2.99s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:08<00:00,  2.74s/it]\n","Train:  30%|███       | 24/80 [08:09<11:17, 12.10s/it, loss=0.01]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  31%|███▏      | 25/80 [08:21<12:31, 13.67s/it, loss=0.011]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  32%|███▎      | 26/80 [08:32<11:48, 13.12s/it, loss=0.0091]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  34%|███▍      | 27/80 [08:39<11:11, 12.67s/it, loss=0.0097]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:02,  2.04s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.59s/it]\n","Train:  34%|███▍      | 27/80 [08:50<11:11, 12.67s/it, loss=0.01] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  35%|███▌      | 28/80 [09:01<12:07, 13.99s/it, loss=0.008] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  36%|███▋      | 29/80 [09:10<11:00, 12.94s/it, loss=0.0075]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  38%|███▊      | 30/80 [09:22<10:04, 12.10s/it, loss=0.006] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  39%|███▉      | 31/80 [09:24<09:53, 12.12s/it, loss=0.0054]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:06<00:00,  2.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  39%|███▉      | 31/80 [09:40<09:53, 12.12s/it, loss=0.0071]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  40%|████      | 32/80 [09:52<10:58, 13.72s/it, loss=0.0059]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  41%|████▏     | 33/80 [10:02<10:17, 13.13s/it, loss=0.0065]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  42%|████▎     | 34/80 [10:09<09:21, 12.20s/it, loss=0.0047]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.07s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.94s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  42%|████▎     | 34/80 [10:19<09:21, 12.20s/it, loss=0.0045]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  44%|████▍     | 35/80 [10:29<10:33, 14.09s/it, loss=0.0044]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  45%|████▌     | 36/80 [10:41<09:14, 12.61s/it, loss=0.004] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  46%|████▋     | 37/80 [10:55<08:48, 12.28s/it, loss=0.0041]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.28s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:02,  2.01s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  48%|████▊     | 38/80 [11:13<10:10, 14.54s/it, loss=0.0033]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  49%|████▉     | 39/80 [11:21<09:19, 13.66s/it, loss=0.0045]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  50%|█████     | 40/80 [11:33<08:17, 12.45s/it, loss=0.0034]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  51%|█████▏    | 41/80 [11:38<07:49, 12.03s/it, loss=0.0029]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:03<00:07,  3.97s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:02,  2.82s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  51%|█████▏    | 41/80 [11:50<07:49, 12.03s/it, loss=0.0028]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  52%|█████▎    | 42/80 [12:02<08:38, 13.64s/it, loss=0.0028]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  54%|█████▍    | 43/80 [12:14<08:00, 13.00s/it, loss=0.003] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  55%|█████▌    | 44/80 [12:22<07:32, 12.58s/it, loss=0.0034]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:05,  2.65s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:03,  3.01s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n","Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  56%|█████▋    | 45/80 [12:41<08:13, 14.11s/it, loss=0.0033]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  57%|█████▊    | 46/80 [12:52<07:31, 13.27s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  59%|█████▉    | 47/80 [13:04<06:43, 12.22s/it, loss=0.0029]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  60%|██████    | 48/80 [13:08<06:27, 12.10s/it, loss=0.0029]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.16s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:02,  2.88s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]\n","Train:  60%|██████    | 48/80 [13:22<06:27, 12.10s/it, loss=0.003] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  61%|██████▏   | 49/80 [13:32<07:02, 13.64s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  62%|██████▎   | 50/80 [13:43<06:32, 13.07s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  64%|██████▍   | 51/80 [13:52<05:59, 12.40s/it, loss=0.0024]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.08s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:02,  2.00s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.51s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["\rTrain:  64%|██████▍   | 51/80 [14:02<05:59, 12.40s/it, loss=0.0034]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  65%|██████▌   | 52/80 [14:12<06:36, 14.14s/it, loss=0.0029]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  66%|██████▋   | 53/80 [14:23<05:42, 12.69s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  68%|██████▊   | 54/80 [14:34<05:18, 12.25s/it, loss=0.0026]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  69%|██████▉   | 55/80 [14:37<05:00, 12.04s/it, loss=0.0025]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.16s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:01,  1.98s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]\n","Train:  69%|██████▉   | 55/80 [14:53<05:00, 12.04s/it, loss=0.0032]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  70%|███████   | 56/80 [15:05<05:43, 14.31s/it, loss=0.0026]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  71%|███████▏  | 57/80 [15:15<05:10, 13.49s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  72%|███████▎  | 58/80 [15:24<04:28, 12.21s/it, loss=0.0027]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:01<00:03,  1.93s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]\n","Train:  72%|███████▎  | 58/80 [15:33<04:28, 12.21s/it, loss=0.0029]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  74%|███████▍  | 59/80 [15:42<04:53, 13.96s/it, loss=0.0024]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  75%|███████▌  | 60/80 [15:54<04:17, 12.85s/it, loss=0.003] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  76%|███████▋  | 61/80 [16:05<03:56, 12.44s/it, loss=0.0026]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  78%|███████▊  | 62/80 [16:08<03:38, 12.15s/it, loss=0.0022]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.16s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  78%|███████▊  | 62/80 [16:24<03:38, 12.15s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  79%|███████▉  | 63/80 [16:34<03:52, 13.70s/it, loss=0.003] "]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  80%|████████  | 64/80 [16:43<03:21, 12.62s/it, loss=0.0026]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  81%|████████▏ | 65/80 [16:52<03:00, 12.01s/it, loss=0.0027]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:05,  2.57s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:04<00:02,  2.17s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]\n","Train:  81%|████████▏ | 65/80 [17:01<03:00, 12.01s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  82%|████████▎ | 66/80 [17:13<03:11, 13.67s/it, loss=0.0025]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  84%|████████▍ | 67/80 [17:25<02:49, 13.03s/it, loss=0.0023]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  85%|████████▌ | 68/80 [17:34<02:30, 12.55s/it, loss=0.0023]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:03<00:06,  3.26s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:02,  2.87s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.58s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n","Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  86%|████████▋ | 69/80 [17:52<02:34, 14.04s/it, loss=0.0027]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  88%|████████▊ | 70/80 [18:03<02:12, 13.24s/it, loss=0.0021]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  89%|████████▉ | 71/80 [18:14<01:49, 12.13s/it, loss=0.0025]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  90%|█████████ | 72/80 [18:19<01:35, 11.95s/it, loss=0.0025]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:05,  2.89s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:05<00:02,  2.99s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:07<00:00,  2.65s/it]\n","Train:  90%|█████████ | 72/80 [18:32<01:35, 11.95s/it, loss=0.0023]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  91%|█████████▏| 73/80 [18:43<01:34, 13.43s/it, loss=0.0025]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  92%|█████████▎| 74/80 [18:52<01:17, 12.84s/it, loss=0.0022]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  94%|█████████▍| 75/80 [19:06<01:01, 12.30s/it, loss=0.0022]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:01<00:03,  1.98s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.91s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n","Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  95%|█████████▌| 76/80 [19:23<00:58, 14.55s/it, loss=0.0023]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  96%|█████████▋| 77/80 [19:35<00:39, 13.04s/it, loss=0.0022]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  98%|█████████▊| 78/80 [19:46<00:25, 12.59s/it, loss=0.0018]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train:  99%|█████████▉| 79/80 [19:50<00:12, 12.23s/it, loss=0.0019]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n","Validation:  33%|███▎      | 1/3 [00:02<00:04,  2.04s/it]\u001b[A\n","Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]\u001b[A\n","Validation: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]\n","Train:  99%|█████████▉| 79/80 [20:02<00:12, 12.23s/it, loss=0.0024]"]},{"output_type":"stream","name":"stdout","text":["Saving best model...\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 80/80 [20:04<00:00, 15.06s/it, loss=0.0024]\n"]}],"source":["def main():\n","\n","    config = path + 'cfg/config_task3.yaml'\n","    cross_validation = False\n","\n","    with open(config, 'r') as ymlfile:\n","        config = yaml.safe_load(ymlfile)\n","\n","    if cross_validation:\n","        # read splits from file\n","        with open(path + 'data/folds.json', 'r') as f:\n","            folds = json.load(f)\n","            num_folds = len(folds)\n","        for fold in tqdm.trange(num_folds):\n","            start_training(config, path, val_fold=fold)\n","    else:\n","        # train using fold 0 as validation fold\n","        start_training(config, path, val_fold=0)\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"markdown","source":["# Testing the trained model"],"metadata":{"id":"h7xXun43ECjq"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection"],"metadata":{"id":"P9Ymd2CTq8_Z","executionInfo":{"status":"ok","timestamp":1687425811559,"user_tz":-120,"elapsed":19,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ecd18f5-78a5-4b83-a633-cf643be0b299"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold0.pt --threshold 0.4 --validate"],"metadata":{"id":"lAgU3IxsfZYX","executionInfo":{"status":"ok","timestamp":1687428880108,"user_tz":-120,"elapsed":16120,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bffdf4bf-e175-40a4-e9fe-ec57eaadb25b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.4, checkpoint='model_best_fold0.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_32_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.10.output.dense.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'cls.predictions.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Model model_best_fold0.pt resumed from , saving results on this directory...\n","100% 12/12 [00:01<00:00,  6.25it/s]\n","MacroF1: 0.3187741512444828\n","MicroF1: 0.5641025641025641\n","Detection dumped on predictions_thr0.4.json\n","Num memes: 90\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.17      0.27        12\n","           1       0.00      0.00      0.00         4\n","           2       0.12      0.09      0.11        11\n","           3       0.00      0.00      0.00         1\n","           4       0.00      0.00      0.00         3\n","           5       0.33      0.25      0.29         4\n","           6       0.50      0.18      0.27        11\n","           7       0.67      0.40      0.50        15\n","           8       0.50      0.50      0.50         6\n","           9       0.50      0.20      0.29        15\n","          10       0.69      0.83      0.76        41\n","          11       0.33      0.20      0.25         5\n","          12       0.68      0.66      0.67        35\n","          13       0.00      0.00      0.00         0\n","          14       0.00      0.00      0.00         1\n","          15       0.00      0.00      0.00         0\n","          16       0.00      0.00      0.00         4\n","          17       0.00      0.00      0.00         3\n","          18       0.75      0.33      0.46         9\n","          19       0.78      0.84      0.81        62\n","          20       0.00      0.00      0.00         2\n","          21       0.00      0.00      0.00        15\n","          22       0.20      0.17      0.18         6\n","\n","   micro avg       0.65      0.50      0.56       265\n","   macro avg       0.29      0.21      0.23       265\n","weighted avg       0.55      0.50      0.51       265\n"," samples avg       0.61      0.50      0.51       265\n","\n","DONE!\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold0.pt --threshold 0.5 --validate"],"metadata":{"id":"ZojuTTBIbqtf","executionInfo":{"status":"ok","timestamp":1687351566779,"user_tz":-120,"elapsed":11062,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93952c20-a362-4e7f-a2dd-32ca850cef1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.5, checkpoint='model_best_fold0.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_32_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'cls.predictions.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Model model_best_fold0.pt resumed from , saving results on this directory...\n","100% 12/12 [00:03<00:00,  3.22it/s]\n","MacroF1: 0.2904298262124349\n","MicroF1: 0.5333333333333334\n","Detection dumped on predictions_thr0.5.json\n","Num memes: 90\n","DONE!\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold0.pt --threshold 0.8 --validate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_zL13XkfWG7","executionInfo":{"status":"ok","timestamp":1687351575711,"user_tz":-120,"elapsed":8940,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"fef19d59-978d-4a69-83ba-7a6f556440af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.8, checkpoint='model_best_fold0.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_32_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.output.dense.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Model model_best_fold0.pt resumed from , saving results on this directory...\n","100% 12/12 [00:02<00:00,  5.78it/s]\n","MacroF1: 0.24169540125509512\n","MicroF1: 0.5098039215686274\n","Detection dumped on predictions_thr0.8.json\n","Num memes: 90\n","DONE!\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold0.pt --threshold 0.9 --validate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZE5pfa-fXjG","executionInfo":{"status":"ok","timestamp":1687351586459,"user_tz":-120,"elapsed":10756,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"b11e682a-f4b2-41b2-907e-662565faf636"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.9, checkpoint='model_best_fold0.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_32_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'cls.predictions.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Model model_best_fold0.pt resumed from , saving results on this directory...\n","100% 12/12 [00:02<00:00,  5.75it/s]\n","MacroF1: 0.20348434040047983\n","MicroF1: 0.4795918367346939\n","Detection dumped on predictions_thr0.9.json\n","Num memes: 90\n","DONE!\n"]}]},{"cell_type":"markdown","source":["## In case there is other saved models"],"metadata":{"id":"kNU8Zm1PEXBd"}},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold1.pt --validate"],"metadata":{"id":"1HLGQ06RaKpG","executionInfo":{"status":"ok","timestamp":1687351590121,"user_tz":-120,"elapsed":3671,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6643239-ab4d-4439-9337-360fa5380a76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.3, checkpoint='model_best_fold1.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 178, in <module>\n","    main(opt)\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 30, in main\n","    checkpoint = torch.load(opt.checkpoint, map_location='cpu')\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'model_best_fold1.pt'\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold2.pt --validate"],"metadata":{"id":"glo2GZM1aK4r","executionInfo":{"status":"ok","timestamp":1687351594125,"user_tz":-120,"elapsed":4010,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"67d59ba7-5b73-437e-8bfc-6c6d3d6bcba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.3, checkpoint='model_best_fold2.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 178, in <module>\n","    main(opt)\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 30, in main\n","    checkpoint = torch.load(opt.checkpoint, map_location='cpu')\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'model_best_fold2.pt'\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold3.pt --validate"],"metadata":{"id":"oggo8QWPaLIh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687351598662,"user_tz":-120,"elapsed":4540,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"7a741bed-c78c-46ff-93d7-31d043e431b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.3, checkpoint='model_best_fold3.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 178, in <module>\n","    main(opt)\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 30, in main\n","    checkpoint = torch.load(opt.checkpoint, map_location='cpu')\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'model_best_fold3.pt'\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold4.pt --validate"],"metadata":{"id":"wKIGKIztaLVe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687351602093,"user_tz":-120,"elapsed":3437,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"db67a06d-0e27-46dd-ddb9-fcb9472fe87a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.3, checkpoint='model_best_fold4.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 178, in <module>\n","    main(opt)\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 30, in main\n","    checkpoint = torch.load(opt.checkpoint, map_location='cpu')\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'model_best_fold4.pt'\n"]}]},{"cell_type":"code","source":["!python inference.py --checkpoint model_best_fold5.pt --validate"],"metadata":{"id":"puD-WerdaOEm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687351605726,"user_tz":-120,"elapsed":3637,"user":{"displayName":"Alban Tchikladze","userId":"15760754508677506322"}},"outputId":"a5d23855-222e-4b8f-8c08-e2012fee6dee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(threshold=0.3, checkpoint='model_best_fold5.pt', validate=True, test=False, val_fold=0, ensemble=False, cross_validation=False)\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 178, in <module>\n","    main(opt)\n","  File \"/content/drive/MyDrive/Telecom/Airbus/Persusasion/MemePersuasionDetection/inference.py\", line 30, in main\n","    checkpoint = torch.load(opt.checkpoint, map_location='cpu')\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'model_best_fold5.pt'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"c7UK1DkpvfM1"},"execution_count":null,"outputs":[]}]}